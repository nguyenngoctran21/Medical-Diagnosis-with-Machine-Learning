{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5264e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of dataset is:  (270, 14)\n",
      "Accuracy of Neural network is: 81 %\n",
      "The confusion matrix is: \n",
      " [[43  7]\n",
      " [ 8 23]]\n",
      "The report is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Absence       0.86      0.84      0.85        51\n",
      "    Presence       0.74      0.77      0.75        30\n",
      "\n",
      "    accuracy                           0.81        81\n",
      "   macro avg       0.80      0.80      0.80        81\n",
      "weighted avg       0.82      0.81      0.82        81\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lnh/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# use pandas library to load data\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('Heart_Disease_Prediction.csv')\n",
    "\n",
    "# print the dataset size \n",
    "print('The size of dataset is: ', dataset.shape)\n",
    "\n",
    "# get all variable in dataset \n",
    "all_var = dataset.columns.tolist()\n",
    "\n",
    "# indicate X, Y \n",
    "\n",
    "ind_var = all_var[0:len(all_var)-1]\n",
    "X = dataset[ind_var]\n",
    "Y = dataset['Heart Disease'].values\n",
    "\n",
    "#Split dataset into training and testing set (25%)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size =0.3)\n",
    "\n",
    "# call algorithm: neural network\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#model_nn = MLPClassifier(hidden_layer_sizes=(15,25,50))\n",
    "#model_nn.fit(X_train,y_train)\n",
    "#y_predict = model_nn.predict(X_test)\n",
    "\n",
    "# call algorithm: Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lg = LogisticRegression()\n",
    "model_lg.fit(X_train,y_train)\n",
    "y_predict = model_lg.predict(X_test)\n",
    "\n",
    "\n",
    "# Keep the result is stable \n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Show the accurracy of prediction \n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('Accuracy of Neural network is: %2.f'%(100*accuracy_score(y_predict,y_test)),'%')\n",
    "\n",
    "# Show the confusion matrix   \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_predict)\n",
    "print('The confusion matrix is: \\n',cm)\n",
    "\n",
    "# Show the classification report \n",
    "from sklearn.metrics import classification_report\n",
    "print ('The report is: \\n',classification_report(y_predict,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cbd4e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of dataset is:  (768, 9)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[342.   0. 210. 105.   0. 265.  90.   0.   0. 132. 304.   0.   0.   0.\n   0.   0.   0. 237.  87.   0.  90.  63.   0.   0.   0.   0.   0.   0.\n 127.   0. 100.   0.   0.   0.   0. 142. 122.   0. 185.   0.   0.   0.\n 148. 180.   0.  53.  36. 392.   0.   0.   0.  71.   0.   0.   0. 180.\n   0. 155. 274.  74. 326. 168.   0.   0.   0. 265.   0.   0.   0.   0.\n 140.   0.   0. 205.   0.  95.   0.   0.   0.   0. 120. 122. 170. 478.\n 125. 231.   0.  66. 100.   0.  74. 846.   0.   0. 116.   0.   0.  57.\n   0.  72.   0. 210.   0. 225.   0. 210.  94.   0. 600. 112.   0.   0.\n 230. 128.   0. 110.   0. 152.   0.   0.   0.  68.   0. 328. 145. 108.\n 190. 165.   0.   0.   0.   0. 159.  90. 167.   0.   0.   0.   0.   0.\n 100.  86.   0. 105.   0. 291.   0.  75.   0. 175.  76.   0.   0.   0.\n   0.  84.   0. 100. 135.   0. 160.  50.  70. 152. 258.   0.  40. 200.\n   0.  37.   0. 110.   0.  73.   0. 165. 318. 180. 120.   0. 215. 270.\n  87. 166. 190. 540.   0. 440. 120. 155.   0.  76.   0.   0. 144.   0.\n   0.   0.  45.   0. 146.   0. 129.   0.   0. 495.   0.   0.   0.   0.\n   0. 106. 140. 321.   0. 220. 140. 156.   0. 170. 744. 185.  14.   0.\n   0. 115. 135.   0. 155. 188.   0.   0. 325. 130.  29. 180. 402.  95.\n   0.  41.  96. 120. 360.   0.   0.  64. 105.   0. 545.   0. 180.   0.\n   0.  89. 168.   0.  57.   0.  23.  54.   0. 148.   0. 240.   0.   0.\n   0.   0. 176.  77.   0.   0. 230.   0. 330.  64.  75. 168.   0.   0.\n 215. 465.   0.  59.   0.  66. 115. 158.   0. 182.   0. 293.  48. 228.\n 160.   0.  78.   0. 105.   0.  94.   0.   0.   0.   0.   0.   0.   0.\n   0.  44.   0. 183.  88. 194.   0. 176.  71.   0.  51.  74. 110.   0.\n   0.   0. 120.   0.  15. 285. 255.  45.   0.   0. 300. 178. 145. 110.\n   0.  60.   0.   0.   0. 194.   0.  56.  76.  46.   0.  67.  49.   0.\n 119.  70. 130. 220.  64.  85. 160.   0.   0.   0.   0. 510.  55.  71.\n 106. 480.   0.   0. 115.   0.   0.  90. 120.   0. 116. 105.   0. 249.\n 335. 180.   0.   0.   0.   0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_115/189001276.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmodel_lg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmodel_lg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1506\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1509\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    770\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[342.   0. 210. 105.   0. 265.  90.   0.   0. 132. 304.   0.   0.   0.\n   0.   0.   0. 237.  87.   0.  90.  63.   0.   0.   0.   0.   0.   0.\n 127.   0. 100.   0.   0.   0.   0. 142. 122.   0. 185.   0.   0.   0.\n 148. 180.   0.  53.  36. 392.   0.   0.   0.  71.   0.   0.   0. 180.\n   0. 155. 274.  74. 326. 168.   0.   0.   0. 265.   0.   0.   0.   0.\n 140.   0.   0. 205.   0.  95.   0.   0.   0.   0. 120. 122. 170. 478.\n 125. 231.   0.  66. 100.   0.  74. 846.   0.   0. 116.   0.   0.  57.\n   0.  72.   0. 210.   0. 225.   0. 210.  94.   0. 600. 112.   0.   0.\n 230. 128.   0. 110.   0. 152.   0.   0.   0.  68.   0. 328. 145. 108.\n 190. 165.   0.   0.   0.   0. 159.  90. 167.   0.   0.   0.   0.   0.\n 100.  86.   0. 105.   0. 291.   0.  75.   0. 175.  76.   0.   0.   0.\n   0.  84.   0. 100. 135.   0. 160.  50.  70. 152. 258.   0.  40. 200.\n   0.  37.   0. 110.   0.  73.   0. 165. 318. 180. 120.   0. 215. 270.\n  87. 166. 190. 540.   0. 440. 120. 155.   0.  76.   0.   0. 144.   0.\n   0.   0.  45.   0. 146.   0. 129.   0.   0. 495.   0.   0.   0.   0.\n   0. 106. 140. 321.   0. 220. 140. 156.   0. 170. 744. 185.  14.   0.\n   0. 115. 135.   0. 155. 188.   0.   0. 325. 130.  29. 180. 402.  95.\n   0.  41.  96. 120. 360.   0.   0.  64. 105.   0. 545.   0. 180.   0.\n   0.  89. 168.   0.  57.   0.  23.  54.   0. 148.   0. 240.   0.   0.\n   0.   0. 176.  77.   0.   0. 230.   0. 330.  64.  75. 168.   0.   0.\n 215. 465.   0.  59.   0.  66. 115. 158.   0. 182.   0. 293.  48. 228.\n 160.   0.  78.   0. 105.   0.  94.   0.   0.   0.   0.   0.   0.   0.\n   0.  44.   0. 183.  88. 194.   0. 176.  71.   0.  51.  74. 110.   0.\n   0.   0. 120.   0.  15. 285. 255.  45.   0.   0. 300. 178. 145. 110.\n   0.  60.   0.   0.   0. 194.   0.  56.  76.  46.   0.  67.  49.   0.\n 119.  70. 130. 220.  64.  85. 160.   0.   0.   0.   0. 510.  55.  71.\n 106. 480.   0.   0. 115.   0.   0.  90. 120.   0. 116. 105.   0. 249.\n 335. 180.   0.   0.   0.   0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# use pandas library to load data\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# print the dataset size \n",
    "print('The size of dataset is: ', dataset.shape)\n",
    "\n",
    "# get all variable in dataset \n",
    "all_var = dataset.columns.tolist()\n",
    "\n",
    "# indicate X, Y \n",
    "\n",
    "ind_var = all_var[0:len(all_var)-1]\n",
    "X = dataset[ind_var]\n",
    "\n",
    "Y = dataset['Outcome'].values\n",
    "\n",
    "#Split dataset into training and testing set (25%)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size =0.5)\n",
    "\n",
    "# call algorithm: neural network\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#model_nn = MLPClassifier(hidden_layer_sizes=(15,25,50))\n",
    "#model_nn.fit(X_train,y_train)\n",
    "#y_predict = model_nn.predict(X_test)\n",
    "\n",
    "# call algorithm: Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lg = LogisticRegression()\n",
    "model_lg.fit(X_train,y_train)\n",
    "y_predict = model_lg.predict(X_test)\n",
    "\n",
    "\n",
    "# Keep the result is stable \n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Show the accurracy of prediction \n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('Accuracy of Neural network is: %2.f'%(100*accuracy_score(y_predict,y_test)),'%')\n",
    "\n",
    "# Show the confusion matrix   \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_predict)\n",
    "print('The confusion matrix is: \\n',cm)\n",
    "\n",
    "# Show the classification report \n",
    "from sklearn.metrics import classification_report\n",
    "print ('The report is: \\n',classification_report(y_predict,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f9178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of dataset is:  (270, 14)\n",
      "Accuracy of Neural network is: 84 %\n",
      "The confusion matrix is: \n",
      " [[33  7]\n",
      " [ 4 24]]\n",
      "The report is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Absence       0.82      0.89      0.86        37\n",
      "    Presence       0.86      0.77      0.81        31\n",
      "\n",
      "    accuracy                           0.84        68\n",
      "   macro avg       0.84      0.83      0.84        68\n",
      "weighted avg       0.84      0.84      0.84        68\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lnh/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# use pandas library to load data\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('Heart_Disease_Prediction.csv')\n",
    "\n",
    "# print the dataset size \n",
    "print('The size of dataset is: ', dataset.shape)\n",
    "\n",
    "# get all variable in dataset \n",
    "all_var = dataset.columns.tolist()\n",
    "\n",
    "# indicate X, Y \n",
    "\n",
    "ind_var = all_var[0:len(all_var)-1]\n",
    "X = dataset[ind_var]\n",
    "Y = dataset['Heart Disease'].values\n",
    "\n",
    "#Split dataset into training and testing set (25%)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size =0.25)\n",
    "\n",
    "# call algorithm: neural network\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#model_nn = MLPClassifier(hidden_layer_sizes=(15,25,50))\n",
    "#model_nn.fit(X_train,y_train)\n",
    "#y_predict = model_nn.predict(X_test)\n",
    "\n",
    "# call algorithm: Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lg = LogisticRegression()\n",
    "model_lg.fit(X_train,y_train)\n",
    "y_predict = model_lg.predict(X_test)\n",
    "\n",
    "\n",
    "# Keep the result is stable \n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Show the accurracy of prediction \n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('Accuracy of Neural network is: %2.f'%(100*accuracy_score(y_predict,y_test)),'%')\n",
    "\n",
    "# Show the confusion matrix   \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_predict)\n",
    "print('The confusion matrix is: \\n',cm)\n",
    "\n",
    "# Show the classification report \n",
    "from sklearn.metrics import classification_report\n",
    "print ('The report is: \\n',classification_report(y_predict,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d50274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of dataset is:  (768, 9)\n",
      "Accuracy of Neural network is: 79 %\n",
      "The confusion matrix is: \n",
      " [[115  15]\n",
      " [ 25  37]]\n",
      "The report is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       140\n",
      "           1       0.60      0.71      0.65        52\n",
      "\n",
      "    accuracy                           0.79       192\n",
      "   macro avg       0.74      0.77      0.75       192\n",
      "weighted avg       0.81      0.79      0.80       192\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lnh/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# use pandas library to load data\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# print the dataset size \n",
    "print('The size of dataset is: ', dataset.shape)\n",
    "\n",
    "# get all variable in dataset \n",
    "all_var = dataset.columns.tolist()\n",
    "\n",
    "# indicate X, Y \n",
    "\n",
    "ind_var = all_var[0:len(all_var)-1]\n",
    "X = dataset[ind_var]\n",
    "Y = dataset['Outcome'].values\n",
    "\n",
    "#Split dataset into training and testing set (25%)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size =0.25)\n",
    "\n",
    "# call algorithm: neural network\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#model_nn = MLPClassifier(hidden_layer_sizes=(15,25,50))\n",
    "#model_nn.fit(X_train,y_train)\n",
    "#y_predict = model_nn.predict(X_test)\n",
    "\n",
    "# call algorithm: Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lg = LogisticRegression()\n",
    "model_lg.fit(X_train,y_train)\n",
    "y_predict = model_lg.predict(X_test)\n",
    "\n",
    "\n",
    "# Keep the result is stable \n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Show the accurracy of prediction \n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('Accuracy of Neural network is: %2.f'%(100*accuracy_score(y_predict,y_test)),'%')\n",
    "\n",
    "# Show the confusion matrix   \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_predict)\n",
    "print('The confusion matrix is: \\n',cm)\n",
    "\n",
    "# Show the classification report \n",
    "from sklearn.metrics import classification_report\n",
    "print ('The report is: \\n',classification_report(y_predict,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1384f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas library to load data\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('Heart_Disease_Prediction.csv')\n",
    "\n",
    "# print the dataset size \n",
    "print('The size of dataset is: ', dataset.shape)\n",
    "\n",
    "# get all variable in dataset \n",
    "all_var = dataset.columns.tolist()\n",
    "\n",
    "# indicate X, Y \n",
    "\n",
    "ind_var = all_var[0:len(all_var)-1]\n",
    "X = dataset[ind_var]\n",
    "Y = dataset['Heart Disease'].values\n",
    "\n",
    "#Split dataset into training and testing set (25%)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size =0.25)\n",
    "\n",
    "# call algorithm: neural network\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#model_nn = MLPClassifier(hidden_layer_sizes=(15,25,50))\n",
    "#model_nn.fit(X_train,y_train)\n",
    "#y_predict = model_nn.predict(X_test)\n",
    "\n",
    "# call algorithm: Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lg = LogisticRegression()\n",
    "\n",
    "model_lg.fit(X_train,y_train)\n",
    "y_predict = model_lg.predict(X_test)\n",
    "\n",
    "\n",
    "# Keep the result is stable \n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Show the accurracy of prediction \n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('Accuracy of Neural network is: %2.f'%(100*accuracy_score(y_predict,y_test)),'%')\n",
    "\n",
    "# Show the confusion matrix   \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_predict)\n",
    "print('The confusion matrix is: \\n',cm)\n",
    "\n",
    "# Show the classification report \n",
    "from sklearn.metrics import classification_report\n",
    "print ('The report is: \\n',classification_report(y_predict,y_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
